Tidying the UCI HAR data set
========================================================

This script uses data from the UCI Machine Learning Repository :

**Human Activity Recognition Using Smartphones Data Set**

http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones

*Associated research*

Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. 
"Human Activity Recognition on Smartphones using a Multiclass Hardware-Friendly Support Vector Machine." International Workshop of Ambient Assisted Living (IWAAL 2012). 
Vitoria-Gasteiz, Spain. Dec 2012

### Preamble

*Last minute addendum (Tuesday April 29th)*
 - I was so stuck on the 5 key instructions of the project ssignment that I didn't remember we should submit a code book, which is actually partially shown in this README but not as clearly as it should. So you will find a file CodeBook.md at the root of this repository.
 - I also realized the instructions confused me in thinking the expected tidy dataset should be comprised of one single table. This is just plain stupid of me, a tidy dataset is actually made of several data frames that you can join if needed, with each reference data frame containing single observational units. In our case the subject is our observational unit so I finally split the initial single dataframe I submitted into several dataframes (one per activity, see at end of this README).
 
*End of last minute edit*

This README was written with the knitr pacakge. In RStudio you should actually be able to open tidy.Rmd and run the "Knit HTML" command in the script editor toolbar. It will execute all the R code chunks contained in the Rmd file.

If you ever want to adopt "Rmd-first" coding practices you can still extract the R code from the Rmd file like this :
```
library(knitr)
purl("tidy.Rmd", output = "run_analysis.R", documentation = 2)
```

### Step 1 : data merge

The UCI dataset is broken down in several files : predictor features, predicted activities, subject IDs. Each of this 3 sets is further broken down into training (70% of entire dataset) and test set (remaining 30%). 

Let's start by loading feature labels from provided file :
```{r}
features <- read.table("features.txt", header=FALSE, stringsAsFactors=FALSE)
names(features) <- c("id","name")
```
Then let's load test data sets :
```{r}
xtest <- read.table("test/X_test.txt")
names(xtest) <- features$name
ytest <- read.table("test/y_test.txt")
names(ytest) <- c("activity_id")
stest <- read.table("test/subject_test.txt")
names(stest) <- c("subject_id")
```
Merge test sets side by side :
```{r}
test <- cbind(stest, xtest, ytest)
```
Let's check dimensions and characteristics of our test data :
```{r}
str(test)
```

Load training sets :
```{r}
xtrain <- read.table("train/X_train.txt")
names(xtrain) <- features$name
ytrain <- read.table("train/y_train.txt")
names(ytrain) <- c("activity_id")
strain <- read.table("train/subject_train.txt")
names(strain) <- c("subject_id")
```
Merge training sets side by side :
```{r}
train <- cbind(strain, xtrain, ytrain)
```
Let's check dimensions and characteristics of our training data :
```{r}
str(train)
```
Now let's append training and test sets together (on top of each other, by rows) :
```{r}
full <- rbind(train,test)
str(full)
```

### Step 2 - select specific features

Pattern matching on columns names can be done with matchcols function in gdata package.
```{r}
install.packages("gdata",repos="http://cran.us.r-project.org") # line added Tue 29th Apr
library(gdata)
```
Match features whose name contain string "mean()" or string "std()" using a regular expression (we make sure to use double backslash to escape parenthesis) :
```{r}
meanstdcols <- matchcols(full, with=c("mean\\(\\)|std\\(\\)"))
```
Ok now let's build a lighter dataset with subject, activity and only mean and std features :
```{r}
sams <- full[,c("subject_id", "activity_id", meanstdcols)]
```

### Step 3 - add activity labels

Load activty labels from provided file :
```{r}
activity <- read.table("activity_labels.txt", stringsAsFactors=FALSE)
names(activity) <- c("activity_id","activity_label")
```
Include explicit activity labels in dataset by merging on activity id :
```{r}
samsExplicit <- merge(sams, activity, by="activity_id")
```

### Step 4 - make feature names more explicit

After checking on the forums there is consensus about a possible typo in the question (see https://class.coursera.org/getdata-002/forum/thread?thread_id=28#post-461). I could have blindly applied gsub to all names. I decided to be a bit more selective and chose to loop only over feature names to make them more explicit.
```{r}
originalNames <- names(samsExplicit)
dontTouch <- c("activity_id","subject_id","activity_label")

for( i in 1:length(originalNames) ){
  name <- originalNames[i]
  # tidy up only if current column name is a feature column name
  # use naive regular expressions to perform substitutions
  if( ! name %in% dontTouch ) {
      a <- gsub("^t", "Time Domain ", name )
      a <- gsub("^f", "Frequency Domain ", a)
      a <- gsub("std\\(\\)", "Standard Deviation ", a)
      a <- gsub("mean\\(\\)", "Mean ", a)
      a <- gsub("-", "", a)
      a <- gsub("Acc", "Linear Acceleration ", a)
      a <- gsub("Jerk", "Jerk ", a)
      a <- gsub("Gyro", "Angular Velocity ", a)
      a <- gsub("Mag","Magnitude ", a)
      a <- gsub("Body", "Body ", a)
      a <- gsub("Gravity", "Gravity ", a)
      # proceed with renaming of current column
      names(samsExplicit)[names(samsExplicit)==name] <- a
  }
}
```
Quick check of what our column names look like now :
```{r}
names(samsExplicit)
```

### Step 5 - compute aggregates and save 

Let's create a new dataset showing means of all feature columns grouped by subject_id and activity_label. Since there are 30 individuals and 6 activities, we should end up with 180 rows in the result data frame. We specify feature colums with robust named exclusion rather than specific indices inclusion.
```{r}
samsAggregate <- aggregate( samsExplicit[,-which(names(samsExplicit) %in% dontTouch)], 
                            by=list(samsExplicit$subject_id, samsExplicit$activity_label),
                            FUN=mean)
```
Checking row count:
```{r}
nrow(samsAggregate)
```
Checking our column names are preserved:
```{r}
names(samsAggregate)
```
Bummer, the aggregate function renamed our grouped by cols, let's fix this.
```{r}
names(samsAggregate)[names(samsAggregate)=="Group.1"] <- "subject_id"
names(samsAggregate)[names(samsAggregate)=="Group.2"] <- "activity_label"
head(samsAggregate[,1:3],n=60)
```
Ah, I'd like the ordering to be subject first, activity second. Let's do this:
```{r}
samsAggregateFinal <- samsAggregate[order(samsAggregate$subject_id, 
                                          samsAggregate$activity_label),]
rownames(samsAggregateFinal) <- NULL
head(samsAggregateFinal[,1:3],n=18)
```
All good. Interestingly enough, the average body acceleration on X axis seem to stack up nicely based on related activities for subject 1, not as clearly for subjects 2 and 3... But this kind of analysis is out of scope for now and could be a good topic to further expand on. We can now write our tidy aggregates to text file and upload this dataset for peer assessment.
```{r}
write.table(samsAggregateFinal,file="tidyAggregates.txt",sep=" ",col.names=TRUE,row.names=FALSE)
```

**added on Tue 29th Apr**

I actually realized I didn't have single observational units in my data frame, so although it feels tidy it is not 100% tidy. Let's simply create one data frame for each activity.
```{r}
tidy <- split(samsAggregateFinal,samsAggregateFinal$activity_label)
for( df in tidy ) {
  write.table(df,file=paste("tidy",df[1,2],".txt",sep="_"),sep=" ",col.names=TRUE,row.names=FALSE)
}
```
You now have a tidy dataset, with 6 files (one per activity) holding 30 records each (one per subject).



